[
  {
    "description": "Correct Doctype lowercase",
    "input": "<!DOCTYPE html>",
    "output": [
      {
        "token-type": "DOCTYPE",
        "name": "html",
        "public-identifier": "missing",
        "system-identifier": "missing",
        "force-quirks": true
      }
    ],
    "id": "tokenizer@test1#0"
  },
  {
    "description": "Correct Doctype uppercase",
    "input": "<!DOCTYPE HTML>",
    "output": [
      {
        "token-type": "DOCTYPE",
        "name": "html",
        "public-identifier": "missing",
        "system-identifier": "missing",
        "force-quirks": true
      }
    ],
    "id": "tokenizer@test1#1"
  },
  {
    "description": "Correct Doctype mixed case",
    "input": "<!DOCTYPE HtMl>",
    "output": [
      {
        "token-type": "DOCTYPE",
        "name": "html",
        "public-identifier": "missing",
        "system-identifier": "missing",
        "force-quirks": true
      }
    ],
    "id": "tokenizer@test1#2"
  },
  {
    "description": "Correct Doctype case with EOF",
    "input": "<!DOCTYPE HtMl",
    "output": [
      {
        "token-type": "DOCTYPE",
        "name": "html",
        "public-identifier": "missing",
        "system-identifier": "missing",
        "force-quirks": false
      }
    ],
    "errors": [
      {
        "code": "eof-in-doctype",
        "line": 1,
        "col": 15
      }
    ],
    "id": "tokenizer@test1#3"
  },
  {
    "description": "Truncated doctype start",
    "input": "<!DOC>",
    "output": [
      {
        "token-type": "comment",
        "data": "DOC"
      }
    ],
    "errors": [
      {
        "code": "incorrectly-opened-comment",
        "line": 1,
        "col": 3
      }
    ],
    "id": "tokenizer@test1#4"
  },
  {
    "description": "Doctype in error",
    "input": "<!DOCTYPE foo>",
    "output": [
      {
        "token-type": "DOCTYPE",
        "name": "foo",
        "public-identifier": "missing",
        "system-identifier": "missing",
        "force-quirks": true
      }
    ],
    "id": "tokenizer@test1#5"
  },
  {
    "description": "Single Start Tag",
    "input": "<h>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": []
      }
    ],
    "id": "tokenizer@test1#6"
  },
  {
    "description": "Empty end tag",
    "input": "</>",
    "output": [],
    "errors": [
      {
        "code": "missing-end-tag-name",
        "line": 1,
        "col": 3
      }
    ],
    "id": "tokenizer@test1#7"
  },
  {
    "description": "Empty start tag",
    "input": "<>",
    "output": [
      {
        "token-type": "character",
        "data": "<>"
      }
    ],
    "errors": [
      {
        "code": "invalid-first-character-of-tag-name",
        "line": 1,
        "col": 2
      }
    ],
    "id": "tokenizer@test1#8"
  },
  {
    "description": "Start Tag w/attribute",
    "input": "<h a='b'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "b"
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#9"
  },
  {
    "description": "Start Tag w/attribute no quotes",
    "input": "<h a=b>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "b"
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#10"
  },
  {
    "description": "Start/End Tag",
    "input": "<h></h>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": []
      },
      {
        "token-type": "end-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": []
      }
    ],
    "id": "tokenizer@test1#11"
  },
  {
    "description": "Two unclosed start tags",
    "input": "<p>One<p>Two",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "p",
        "self-closing-flag": "unset",
        "attributes": []
      },
      {
        "token-type": "character",
        "data": "One"
      },
      {
        "token-type": "start-tag",
        "tag-name": "p",
        "self-closing-flag": "unset",
        "attributes": []
      },
      {
        "token-type": "character",
        "data": "Two"
      }
    ],
    "id": "tokenizer@test1#12"
  },
  {
    "description": "End Tag w/attribute",
    "input": "<h></h a='b'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": []
      },
      {
        "token-type": "end-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": []
      }
    ],
    "errors": [
      {
        "code": "end-tag-with-attributes",
        "line": 1,
        "col": 13
      }
    ],
    "id": "tokenizer@test1#13"
  },
  {
    "description": "Multiple atts",
    "input": "<h a='b' c='d'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "b"
          ],
          [
            "c",
            "d"
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#14"
  },
  {
    "description": "Multiple atts no space",
    "input": "<h a='b'c='d'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "b"
          ],
          [
            "c",
            "d"
          ]
        ]
      }
    ],
    "errors": [
      {
        "code": "missing-whitespace-between-attributes",
        "line": 1,
        "col": 9
      }
    ],
    "id": "tokenizer@test1#15"
  },
  {
    "description": "Repeated attr",
    "input": "<h a='b' a='d'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "b"
          ]
        ]
      }
    ],
    "errors": [
      {
        "code": "duplicate-attribute",
        "line": 1,
        "col": 11
      }
    ],
    "id": "tokenizer@test1#16"
  },
  {
    "description": "Simple comment",
    "input": "<!--comment-->",
    "output": [
      {
        "token-type": "comment",
        "data": "comment"
      }
    ],
    "id": "tokenizer@test1#17"
  },
  {
    "description": "Comment, Central dash no space",
    "input": "<!----->",
    "output": [
      {
        "token-type": "comment",
        "data": "-"
      }
    ],
    "id": "tokenizer@test1#18"
  },
  {
    "description": "Comment, two central dashes",
    "input": "<!-- --comment -->",
    "output": [
      {
        "token-type": "comment",
        "data": " --comment "
      }
    ],
    "id": "tokenizer@test1#19"
  },
  {
    "description": "Comment, central less-than bang",
    "input": "<!--<!-->",
    "output": [
      {
        "token-type": "comment",
        "data": "<!"
      }
    ],
    "id": "tokenizer@test1#20"
  },
  {
    "description": "Unfinished comment",
    "input": "<!--comment",
    "output": [
      {
        "token-type": "comment",
        "data": "comment"
      }
    ],
    "errors": [
      {
        "code": "eof-in-comment",
        "line": 1,
        "col": 12
      }
    ],
    "id": "tokenizer@test1#21"
  },
  {
    "description": "Unfinished comment after start of nested comment",
    "input": "<!-- <!--",
    "output": [
      {
        "token-type": "comment",
        "data": " <!"
      }
    ],
    "errors": [
      {
        "code": "eof-in-comment",
        "line": 1,
        "col": 10
      }
    ],
    "id": "tokenizer@test1#22"
  },
  {
    "description": "Start of a comment",
    "input": "<!-",
    "output": [
      {
        "token-type": "comment",
        "data": "-"
      }
    ],
    "errors": [
      {
        "code": "incorrectly-opened-comment",
        "line": 1,
        "col": 3
      }
    ],
    "id": "tokenizer@test1#23"
  },
  {
    "description": "Short comment",
    "input": "<!-->",
    "output": [
      {
        "token-type": "comment",
        "data": ""
      }
    ],
    "errors": [
      {
        "code": "abrupt-closing-of-empty-comment",
        "line": 1,
        "col": 5
      }
    ],
    "id": "tokenizer@test1#24"
  },
  {
    "description": "Short comment two",
    "input": "<!--->",
    "output": [
      {
        "token-type": "comment",
        "data": ""
      }
    ],
    "errors": [
      {
        "code": "abrupt-closing-of-empty-comment",
        "line": 1,
        "col": 6
      }
    ],
    "id": "tokenizer@test1#25"
  },
  {
    "description": "Short comment three",
    "input": "<!---->",
    "output": [
      {
        "token-type": "comment",
        "data": ""
      }
    ],
    "id": "tokenizer@test1#26"
  },
  {
    "description": "< in comment",
    "input": "<!-- <test-->",
    "output": [
      {
        "token-type": "comment",
        "data": " <test"
      }
    ],
    "id": "tokenizer@test1#27"
  },
  {
    "description": "<! in comment",
    "input": "<!-- <!test-->",
    "output": [
      {
        "token-type": "comment",
        "data": " <!test"
      }
    ],
    "id": "tokenizer@test1#28"
  },
  {
    "description": "<!- in comment",
    "input": "<!-- <!-test-->",
    "output": [
      {
        "token-type": "comment",
        "data": " <!-test"
      }
    ],
    "id": "tokenizer@test1#29"
  },
  {
    "description": "Nested comment",
    "input": "<!-- <!--test-->",
    "output": [
      {
        "token-type": "comment",
        "data": " <!--test"
      }
    ],
    "errors": [
      {
        "code": "nested-comment",
        "line": 1,
        "col": 10
      }
    ],
    "id": "tokenizer@test1#30"
  },
  {
    "description": "Nested comment with extra <",
    "input": "<!-- <<!--test-->",
    "output": [
      {
        "token-type": "comment",
        "data": " <<!--test"
      }
    ],
    "errors": [
      {
        "code": "nested-comment",
        "line": 1,
        "col": 11
      }
    ],
    "id": "tokenizer@test1#31"
  },
  {
    "description": "< in script data",
    "initialStates": [
      "Script data state"
    ],
    "input": "<test-->",
    "output": [
      {
        "token-type": "character",
        "data": "<test-->"
      }
    ],
    "id": "tokenizer@test1#32"
  },
  {
    "description": "<! in script data",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!test-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!test-->"
      }
    ],
    "id": "tokenizer@test1#33"
  },
  {
    "description": "<!- in script data",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!-test-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!-test-->"
      }
    ],
    "id": "tokenizer@test1#34"
  },
  {
    "description": "Escaped script data",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!--test-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!--test-->"
      }
    ],
    "id": "tokenizer@test1#35"
  },
  {
    "description": "< in script HTML comment",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!-- < test -->",
    "output": [
      {
        "token-type": "character",
        "data": "<!-- < test -->"
      }
    ],
    "id": "tokenizer@test1#36"
  },
  {
    "description": "</ in script HTML comment",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!-- </ test -->",
    "output": [
      {
        "token-type": "character",
        "data": "<!-- </ test -->"
      }
    ],
    "id": "tokenizer@test1#37"
  },
  {
    "description": "Start tag in script HTML comment",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!-- <test> -->",
    "output": [
      {
        "token-type": "character",
        "data": "<!-- <test> -->"
      }
    ],
    "id": "tokenizer@test1#38"
  },
  {
    "description": "End tag in script HTML comment",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!-- </test> -->",
    "output": [
      {
        "token-type": "character",
        "data": "<!-- </test> -->"
      }
    ],
    "id": "tokenizer@test1#39"
  },
  {
    "description": "- in script HTML comment double escaped",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!--<script>-</script>-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!--<script>-</script>-->"
      }
    ],
    "id": "tokenizer@test1#40"
  },
  {
    "description": "-- in script HTML comment double escaped",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!--<script>--</script>-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!--<script>--</script>-->"
      }
    ],
    "id": "tokenizer@test1#41"
  },
  {
    "description": "--- in script HTML comment double escaped",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!--<script>---</script>-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!--<script>---</script>-->"
      }
    ],
    "id": "tokenizer@test1#42"
  },
  {
    "description": "- spaced in script HTML comment double escaped",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!--<script> - </script>-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!--<script> - </script>-->"
      }
    ],
    "id": "tokenizer@test1#43"
  },
  {
    "description": "-- spaced in script HTML comment double escaped",
    "initialStates": [
      "Script data state"
    ],
    "input": "<!--<script> -- </script>-->",
    "output": [
      {
        "token-type": "character",
        "data": "<!--<script> -- </script>-->"
      }
    ],
    "id": "tokenizer@test1#44"
  },
  {
    "description": "Ampersand EOF",
    "input": "&",
    "output": [
      {
        "token-type": "character",
        "data": "&"
      }
    ],
    "id": "tokenizer@test1#45"
  },
  {
    "description": "Ampersand ampersand EOF",
    "input": "&&",
    "output": [
      {
        "token-type": "character",
        "data": "&&"
      }
    ],
    "id": "tokenizer@test1#46"
  },
  {
    "description": "Ampersand space EOF",
    "input": "& ",
    "output": [
      {
        "token-type": "character",
        "data": "& "
      }
    ],
    "id": "tokenizer@test1#47"
  },
  {
    "description": "Unfinished entity",
    "input": "&f",
    "output": [
      {
        "token-type": "character",
        "data": "&f"
      }
    ],
    "id": "tokenizer@test1#48"
  },
  {
    "description": "Ampersand, number sign",
    "input": "&#",
    "output": [
      {
        "token-type": "character",
        "data": "&#"
      }
    ],
    "errors": [
      {
        "code": "absence-of-digits-in-numeric-character-reference",
        "line": 1,
        "col": 3
      }
    ],
    "id": "tokenizer@test1#49"
  },
  {
    "description": "Unfinished numeric entity",
    "input": "&#x",
    "output": [
      {
        "token-type": "character",
        "data": "&#x"
      }
    ],
    "errors": [
      {
        "code": "absence-of-digits-in-numeric-character-reference",
        "line": 1,
        "col": 4
      }
    ],
    "id": "tokenizer@test1#50"
  },
  {
    "description": "Entity with trailing semicolon (1)",
    "input": "I'm &not;it",
    "output": [
      {
        "token-type": "character",
        "data": "I'm \u00acit"
      }
    ],
    "id": "tokenizer@test1#51"
  },
  {
    "description": "Entity with trailing semicolon (2)",
    "input": "I'm &notin;",
    "output": [
      {
        "token-type": "character",
        "data": "I'm \u2209"
      }
    ],
    "id": "tokenizer@test1#52"
  },
  {
    "description": "Entity without trailing semicolon (1)",
    "input": "I'm &notit",
    "output": [
      {
        "token-type": "character",
        "data": "I'm \u00acit"
      }
    ],
    "errors": [
      {
        "code": "missing-semicolon-after-character-reference",
        "line": 1,
        "col": 9
      }
    ],
    "id": "tokenizer@test1#53"
  },
  {
    "description": "Entity without trailing semicolon (2)",
    "input": "I'm &notin",
    "output": [
      {
        "token-type": "character",
        "data": "I'm \u00acin"
      }
    ],
    "errors": [
      {
        "code": "missing-semicolon-after-character-reference",
        "line": 1,
        "col": 9
      }
    ],
    "id": "tokenizer@test1#54"
  },
  {
    "description": "Partial entity match at end of file",
    "input": "I'm &no",
    "output": [
      {
        "token-type": "character",
        "data": "I'm &no"
      }
    ],
    "id": "tokenizer@test1#55"
  },
  {
    "description": "Non-ASCII character reference name",
    "input": "&\u00ac;",
    "output": [
      {
        "token-type": "character",
        "data": "&\u00ac;"
      }
    ],
    "id": "tokenizer@test1#56"
  },
  {
    "description": "ASCII decimal entity",
    "input": "&#0036;",
    "output": [
      {
        "token-type": "character",
        "data": "$"
      }
    ],
    "id": "tokenizer@test1#57"
  },
  {
    "description": "ASCII hexadecimal entity",
    "input": "&#x3f;",
    "output": [
      {
        "token-type": "character",
        "data": "?"
      }
    ],
    "id": "tokenizer@test1#58"
  },
  {
    "description": "Hexadecimal entity in attribute",
    "input": "<h a='&#x3f;'></h>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "?"
          ]
        ]
      },
      {
        "token-type": "end-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": []
      }
    ],
    "id": "tokenizer@test1#59"
  },
  {
    "description": "Entity in attribute without semicolon ending in x",
    "input": "<h a='&notx'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "&notx"
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#60"
  },
  {
    "description": "Entity in attribute without semicolon ending in 1",
    "input": "<h a='&not1'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "&not1"
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#61"
  },
  {
    "description": "Entity in attribute without semicolon ending in i",
    "input": "<h a='&noti'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "&noti"
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#62"
  },
  {
    "description": "Entity in attribute without semicolon",
    "input": "<h a='&COPY'>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "h",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "\u00a9"
          ]
        ]
      }
    ],
    "errors": [
      {
        "code": "missing-semicolon-after-character-reference",
        "line": 1,
        "col": 12
      }
    ],
    "id": "tokenizer@test1#63"
  },
  {
    "description": "Unquoted attribute ending in ampersand",
    "input": "<s o=& t>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "s",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "o",
            "&"
          ],
          [
            "t",
            ""
          ]
        ]
      }
    ],
    "id": "tokenizer@test1#64"
  },
  {
    "description": "Unquoted attribute at end of tag with final character of &, with tag followed by characters",
    "input": "<a a=a&>foo",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "a",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "a&"
          ]
        ]
      },
      {
        "token-type": "character",
        "data": "foo"
      }
    ],
    "id": "tokenizer@test1#65"
  },
  {
    "description": "plaintext element",
    "input": "<plaintext>foobar",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "plaintext",
        "self-closing-flag": "unset",
        "attributes": []
      },
      {
        "token-type": "character",
        "data": "foobar"
      }
    ],
    "id": "tokenizer@test1#66"
  },
  {
    "description": "Open angled bracket in unquoted attribute value state",
    "input": "<a a=f<>",
    "output": [
      {
        "token-type": "start-tag",
        "tag-name": "a",
        "self-closing-flag": "unset",
        "attributes": [
          [
            "a",
            "f<"
          ]
        ]
      }
    ],
    "errors": [
      {
        "code": "unexpected-character-in-unquoted-attribute-value",
        "line": 1,
        "col": 7
      }
    ],
    "id": "tokenizer@test1#67"
  }
]